# WeightedConsistentHash Strategy - Design Document

**Status**: ✅ Design Approved - Ready for Implementation
**Created**: November 1, 2025
**Approved**: November 1, 2025
**Target**: v1.1.0 (Phase 4 - Assignment Edge Cases)
**Estimated Effort**: 3-4 hours implementation + 1 hour testing

---

## 1. Problem Statement

### Current State
- ✅ `ConsistentHash` strategy exists - provides partition stability via consistent hashing
- ✅ `RoundRobin` strategy exists - simple round-robin distribution
- ✅ `WeightedRing` implementation exists in `internal/hash/ring.go` (unused)
- ❌ **No strategy uses partition weights for load balancing**

### Library Specification Says:
```
Default: WeightedConsistentHashStrategy(150)
- Weighted Assignment: Supports partition weights for load balancing
```

### The Problem
Users cannot balance load when partitions have vastly different computational costs:
- **Weight represents**: Bytes to process per batch (memory + processing time)
- **Real-world variance**: 100x-500x difference between partitions
- **Example**: Normal partition = 100 bytes, Extreme partition = 50,000 bytes
- **Without weights**: Some workers get 10x more load than others
- **Impact**: Resource exhaustion, OOM, uneven latency

---

## 2. Design Goals

### Primary Goals
1. **Load Balancing**: Distribute partitions based on weight to prevent overloaded workers
2. **Cache Affinity**: Maintain >80% partition stability during rebalancing (like ConsistentHash)
3. **Fair Distribution**: Each worker gets approximately equal total weight

### Non-Goals
- Perfect weight distribution (some variance acceptable)
- Support for dynamic weight updates (weights static per rebalance)
- Worker-level capacity constraints (all workers assumed equal capacity)

---

## 3. Algorithm Design

### 3.1 Core Algorithm (from existing WeightedRing)

```go
// From internal/hash/ring.go - WeightedRing.AssignPartitions()

1. Calculate total weight and average per worker:
   totalWeight = sum(partition.Weight for all partitions)
   avgWeight = totalWeight / numWorkers
   maxWeight = avgWeight * 1.15  // Allow 15% variance

2. For each partition:
   a. Get consistent hash candidate: worker = ring.GetNode(partition.Keys)
   b. Check if adding partition would overload candidate:
      if workerWeights[worker] + partition.Weight > maxWeight:
         worker = findLightestWorker()  // Fallback to lightest worker
   c. Assign partition to worker
   d. Update workerWeights[worker] += partition.Weight

3. Return assignments
```

### 3.2 Key Design Decisions

#### Before Decision
Our scenario should consider the heavy unequal weight situaion. e.g., 100 vs 10000. the weight might be 10x to 500x.
The weight is usually roughly equal to "bytes for batch that needs to process" in real-world case. It implies that each
worker should create how many memory and spent how many time to process the request.
Weight is also the hint for how many requests can be processed concurrently in the worker.

So we need to discuss about how to identify extreme heavy weighted subjects and assign them to all workers for maximum parallel
processing performance. Or, we need to design a safe way that avoid to let worker OOM.


#### Decision 1: Default Weight Value
**Question**: What should the default weight be when `partition.Weight == 0`?

Current implementation uses `100` as default.

**Options**:
- A) Keep `100` (current)
- B) Use `1` (simpler math)
- C) Make it configurable via option

**Your Input**:
```
[PLEASE RESPOND HERE]

Recommendation:
B). Defaults to `1`


Rationale:


```

---

#### Decision 2: Overload Threshold
**Question**: What's the acceptable variance for weight distribution?

Current implementation uses `115%` of average (15% variance).

**Considerations**:
- **Too tight** (e.g., 105%): May sacrifice cache affinity for perfect balance
- **Too loose** (e.g., 150%): Better cache affinity but uneven load
- **Just right** (115%): Balance between affinity and fairness

**Your Input**:
```
[PLEASE RESPOND HERE]

Preferred threshold:
defaults to 30%, but it needs to be configurable and has lower limitation to 15%

Rationale:


Should this be configurable?: [ o ] Yes  [ ] No
```

---

#### Decision 3: Overload Fallback Strategy
**Question**: When a worker is overloaded, how do we find the next worker?

Current implementation: `findLightestWorker()` - picks worker with minimum current weight

**Options**:
- A) **Lightest Worker** (current): Always pick worker with least weight
  - Pro: Best load balance
  - Con: Ignores consistent hash ring order, reduces cache affinity

- B) **Next on Ring**: Walk clockwise on hash ring until find non-overloaded worker
  - Pro: Better cache affinity (locality preserved)
  - Con: May create cascading overloads

- C) **Hybrid**: Try next 3 on ring, then fallback to lightest
  - Pro: Balance between affinity and fairness
  - Con: More complex

**Your Input**:
```
[PLEASE RESPOND HERE]

Preferred strategy:
C, but we should consider the extreme heavy weight condition, see the `Before Decision` section I mentioned.

Rationale:


```

---

#### Decision 4: Weight Zero Handling
**Question**: How should we handle partitions with weight = 0?

**Options**:
- A) Treat as default weight (100 or 1)
- B) Skip weight balancing, use pure consistent hash
- C) Reject with error

Current implementation: Uses default weight (100)

**Your Input**:
```
[PLEASE RESPOND HERE]

Preferred approach:
A, set to default 1 weight.

Rationale:


```

---

#### Decision 5: All Partitions Same Weight
**Question**: When all partitions have the same weight, should we optimize?

**Scenario**: `[{w:100}, {w:100}, {w:100}, ...]`

**Options**:
- A) **No optimization**: Run weighted algorithm normally
- B) **Short-circuit**: Detect equal weights and use plain ConsistentHash (faster)

**Trade-offs**:
- Short-circuit: Faster, but behavior might differ slightly from weighted algorithm
- No optimization: Simpler code, consistent behavior

**Your Input**:
```
[PLEASE RESPOND HERE]

Preferred approach:
B, use plain ConsistentHash, but once we detect any unequal weight, back to weighted consistent hash

Rationale:


```

---

#### Decision 6: Strategy Naming
**Question**: What should we name this strategy?

**Options**:
- A) `WeightedConsistentHash` (matches spec: "WeightedConsistentHashStrategy")
- B) `ConsistentHashWeighted` (groups with ConsistentHash)
- C) `ConsistentHashWithWeights` (explicit)
- D) Keep simple `ConsistentHash` and add option `WithWeights(true)`

**Your Input**:
```
[PLEASE RESPOND HERE]

Preferred name:
A, WeightedConsistentHash

Rationale:


```

---

### 3.3 Key Design Decisions Round 2

#### How should we handle a partition whose weight ALONE exceeds the per-worker average?
1. Is Option A (accept imbalance) acceptable?
Yes, Option A is acceptable

2. Should we implement Option E (round-robin extremes)?
Yes, round-robin extremes, best-effort

3. Or do you expect partition sources to never create such extreme weights?
No, my use cases is: 95% are normal weight, but 5% are extreme weight


## 4. API Design

### 4.1 Proposed Strategy Interface

```go
// strategy/weighted_consistent_hash.go

package strategy

import (
	"errors"
	"github.com/arloliu/parti/internal/hash"
	"github.com/arloliu/parti/types"
)

// WeightedConsistentHash implements weighted consistent hashing.
//
// Distributes partitions based on weights while maintaining cache affinity.
// Achieves fair load distribution (within 15% variance) while preserving
// >70% partition stability during rebalancing.
type WeightedConsistentHash struct {
	virtualNodes      int
	hashSeed          uint64
	overloadThreshold float64 // Default: 1.15 (115% of average)
	defaultWeight     int64   // Default: 1
}

// NewWeightedConsistentHash creates a weighted consistent hash strategy.
//
// Parameters:
//   - opts: Optional configuration
//
// Returns:
//   - *WeightedConsistentHash: Initialized strategy
//
// Example:
//
//	strategy := strategy.NewWeightedConsistentHash(
//	    strategy.WithVirtualNodes(150),
//	    strategy.WithOverloadThreshold(1.2),
//	)
func NewWeightedConsistentHash(opts ...WeightedConsistentHashOption) *WeightedConsistentHash {
	wch := &WeightedConsistentHash{
		virtualNodes:      150,
		hashSeed:          0,
		overloadThreshold: 1.15,
		defaultWeight:     1,
	}

	for _, opt := range opts {
		opt(wch)
	}

	return wch
}

// Assign calculates weighted assignments using consistent hashing.
//
// Algorithm:
//   1. Build hash ring with virtual nodes
//   2. Calculate average weight per worker
//   3. For each partition:
//      - Get consistent hash candidate
//      - If candidate overloaded, find alternate worker
//      - Assign partition
//
// Parameters:
//   - workers: List of worker IDs
//   - partitions: Partitions with weights
//
// Returns:
//   - map[string][]types.Partition: Assignments
//   - error: If no workers available
func (wch *WeightedConsistentHash) Assign(
	workers []string,
	partitions []types.Partition,
) (map[string][]types.Partition, error) {
	if len(workers) == 0 {
		return nil, errors.New("no workers available for assignment")
	}

	// Create weighted ring
	ring := hash.NewWeighted(workers, wch.virtualNodes, wch.hashSeed)

	// Use WeightedRing's AssignPartitions method
	assignments := ring.AssignPartitions(partitions)

	return assignments, nil
}

// Configuration options
type WeightedConsistentHashOption func(*WeightedConsistentHash)

func WithVirtualNodes(nodes int) WeightedConsistentHashOption {
	return func(wch *WeightedConsistentHash) {
		wch.virtualNodes = nodes
	}
}

func WithOverloadThreshold(threshold float64) WeightedConsistentHashOption {
	return func(wch *WeightedConsistentHash) {
		wch.overloadThreshold = threshold
	}
}

func WithDefaultWeight(weight int64) WeightedConsistentHashOption {
	return func(wch *WeightedConsistentHash) {
		wch.defaultWeight = weight
	}
}

func WithHashSeed(seed uint64) WeightedConsistentHashOption {
	return func(wch *WeightedConsistentHash) {
		wch.hashSeed = seed
	}
}
```

### 4.2 Questions on API Design

**Question A**: Should options be shared between `ConsistentHash` and `WeightedConsistentHash`?

**Current**: Separate option types
- `ConsistentHashOption`
- `WeightedConsistentHashOption`

**Alternative**: Shared option type
- Both use `ConsistentHashOption`
- Allows: `opts := []ConsistentHashOption{WithVirtualNodes(200)}` to work for both

**Your Input**:
```
[PLEASE RESPOND HERE]

Preferred approach:
Shared options if them are common exists in both.
Rationale:


```

---

**Question B**: Should we expose `overloadThreshold` as a configuration option?

**Considerations**:
- **Expose**: Gives users control, but adds complexity
- **Hide**: Simpler API, but users can't fine-tune
- **Reasonable default**: 1.15 (15% variance) works for most cases

**Your Input**:
```
[PLEASE RESPOND HERE]

Should expose?: [ o ] Yes  [ ] No

If no, is 1.15 a good default?:
1.3 is a good default

```

---

## 5. Implementation Plan

### Phase 1: Core Implementation (1 hour)
1. ✅ Review existing `WeightedRing` implementation (already done)
2. Create `strategy/weighted_consistent_hash.go`
3. Implement `NewWeightedConsistentHash()` constructor
4. Implement `Assign()` method (thin wrapper around WeightedRing)
5. Add compile-time interface assertion

### Phase 2: Update WeightedRing if Needed (0-1 hour)
Based on design decisions above, update `internal/hash/ring.go`:
- [ ] Adjust default weight if changed
- [ ] Adjust overload threshold if changed
- [ ] Implement alternate fallback strategy if chosen
- [ ] Add configuration options to WeightedRing

### Phase 3: Testing (1 hour)
1. Add to `strategy/assignment_edge_test.go`:
   - WeightedConsistentHash alongside ConsistentHash and RoundRobin
   - New weight-specific tests
2. Create `strategy/weighted_consistent_hash_test.go`:
   - Weight distribution accuracy
   - Cache affinity preservation
   - Edge cases (all same weight, all zero weight)

### Phase 4: Documentation (0.5 hour)
1. Update `strategy/doc.go` with WeightedConsistentHash
2. Update examples to show weighted partitions
3. Update library-specification.md

---

## 6. Test Plan

### 6.1 Unit Tests (strategy/weighted_consistent_hash_test.go)

```go
// Core behavior tests
TestWeightedConsistentHash_BalancesLoad
TestWeightedConsistentHash_PreservesCacheAffinity
TestWeightedConsistentHash_HandlesZeroWeights
TestWeightedConsistentHash_HandlesEqualWeights

// Edge cases
TestWeightedConsistentHash_ExtremeWeightDifferences
TestWeightedConsistentHash_SingleWorker
TestWeightedConsistentHash_NoWorkers
TestWeightedConsistentHash_NoPartitions

// Comparison tests
TestWeightedConsistentHash_VsConsistentHash_Stability
TestWeightedConsistentHash_VsRoundRobin_Balance
```

### 6.2 Expected Behavior

**Test: Load Balancing with Unequal Weights**
```go
Workers: ["w0", "w1", "w2"]
Partitions: [
    {Keys: ["p0"], Weight: 100},
    {Keys: ["p1"], Weight: 500},  // Heavy
    {Keys: ["p2"], Weight: 100},
    {Keys: ["p3"], Weight: 500},  // Heavy
    {Keys: ["p4"], Weight: 100},
]
Total: 1300, Avg: 433, Max: 498 (15% variance)

Expected:
- Each worker gets total weight between 350-550 (±15%)
- Heavy partitions (500) distributed across different workers
- Light partitions (100) fill gaps
```

**Test: Cache Affinity Preservation**
```go
Initial: 2 workers, 100 partitions (equal weights)
Action: Add 3rd worker
Expected:
- ~33 partitions move to new worker (consistent hash behavior)
- ~67 partitions stay with original workers (>66% stability)
- Weights remain balanced after rebalance
```

---

## 7. Open Questions for Discussion

### Question 1: Integration with Manager
**Context**: How should Manager use this strategy by default?

**Options**:
- A) Make `WeightedConsistentHash` the default (as spec says)
- B) Keep `ConsistentHash` as default (simpler, weights optional)
- C) Auto-detect: if any partition has weight != 100, use weighted

**Your Input**:
```
[PLEASE RESPOND HERE]

Preferred approach:
A

Rationale:


When should users choose ConsistentHash vs WeightedConsistentHash?:


```

---

### Question 2: Performance Impact
**Context**: WeightedRing does extra work (weight tracking, overload checks)

**Estimates**:
- ConsistentHash: O(P × log V) where P=partitions, V=virtual nodes
- WeightedConsistentHash: O(P × log V + P × W) where W=workers (for overload checks)

**For typical case** (100 partitions, 10 workers, 150 vnodes):
- ConsistentHash: ~700 ops
- WeightedConsistentHash: ~1700 ops (~2.4x slower)

**Question**: Is this acceptable?

**Your Input**:
```
[PLEASE RESPOND HERE]

Is 2.4x slowdown acceptable for weighted assignment?:

Should we add performance benchmarks?: [ O ] Yes  [ ] No

Threshold for optimization concerns (e.g., > 5x slower)?:


```

---

### Question 3: Backwards Compatibility
**Question**: What happens if users upgrade and weights change assignments?

**Scenario**: User has ConsistentHash, upgrades to WeightedConsistentHash
- Partitions assigned: `{w0: [p0, p1], w1: [p2, p3]}`
- After upgrade with weights: `{w0: [p0, p3], w1: [p1, p2]}`

**Impact**: Partition movement = cache invalidation

**Your Input**:
```
[PLEASE RESPOND HERE]

Is this acceptable?:
Yes, it's acceptable

Should we version strategies in KV?: [ ] Yes  [ O ] No

Skip KV versioning

Should users opt-in to weighted?: [ ] Yes  [ O ] No
Automatic (No opt-in)

```

---

### Question 4: Future Enhancements
**Question**: What features might we add later?

**Ideas**:
- Worker-level capacity constraints (some workers more powerful)
- Dynamic weight updates (without full rebalance)
- Weight prediction (ML-based partition cost estimation)
- Multi-dimensional weights (CPU, memory, I/O)

**Your Input**:
```
[PLEASE RESPOND HERE]

Priority future features:
1.
2.
3.

Should current design accommodate these?:


```

---

## 8. Success Criteria

### Definition of Done
- [ ] `WeightedConsistentHash` strategy implemented
- [ ] All edge case tests passing (zero weights, equal weights, extreme weights)
- [ ] Load balance within 15% variance verified
- [ ] Cache affinity >70% preserved during rebalance
- [ ] Zero linting issues
- [ ] Documentation updated
- [ ] Design decisions documented with rationale

### Acceptance Tests
```bash
# All tests pass
go test ./strategy -v

# No linting issues
golangci-lint run ./strategy/...

# Load balance test
go test -run TestWeightedConsistentHash_BalancesLoad -v

# Cache affinity test
go test -run TestWeightedConsistentHash_PreservesCacheAffinity -v
```

---

## 9. Timeline

**Total Estimate**: 2-3 hours

- [ ] Design review & decisions: **30 minutes** (this document)
- [ ] Core implementation: **1 hour**
- [ ] WeightedRing adjustments: **0-1 hour** (if needed)
- [ ] Testing: **1 hour**
- [ ] Documentation: **30 minutes**

**Integration into Phase 4**:
- Current Phase 4: Assignment edge cases (1h spent, 2h remaining)
- Add WeightedConsistentHash: +2-3h
- Updated Phase 4: ~4-5h total

---

## 10. Next Steps

### Before Implementation
1. **Review this document** with Arlo
2. **Answer all questions** (marked with `[PLEASE RESPOND HERE]`)
3. **Get alignment** on design decisions
4. **Finalize API design**

### After Approval
1. Implement `strategy/weighted_consistent_hash.go`
2. Update `internal/hash/ring.go` if needed
3. Add comprehensive tests
4. Update Phase 4 edge case tests to include WeightedConsistentHash
5. Update documentation

---

## Appendix A: Comparison Matrix

| Feature | ConsistentHash | RoundRobin | WeightedConsistentHash |
|---------|---------------|------------|----------------------|
| **Load Balance** | Fair (partition count) | Perfect (partition count) | Fair (total weight) |
| **Cache Affinity** | >80% during rebalance | 0% (random) | >70% during rebalance |
| **Uses Weights** | ❌ No | ❌ No | ✅ Yes |
| **Complexity** | O(P log V) | O(P) | O(P log V + PW) |
| **Best For** | Equal partitions, cache important | Simple, no cache | Unequal partitions, cache important |

## Appendix B: Real-World Example

**Scenario**: Tool monitoring with variable SVID counts

```go
partitions := []types.Partition{
    {Keys: []string{"tool001", "chamber1"}, Weight: 1200000}, // 100 SVIDs × 10 Hz × 1200s
    {Keys: []string{"tool001", "chamber2"}, Weight: 30000},   // 50 SVIDs × 1 Hz × 600s
    {Keys: []string{"tool002", "chamber1"}, Weight: 600000},  // 50 SVIDs × 10 Hz × 1200s
    {Keys: []string{"tool002", "chamber2"}, Weight: 15000},   // 25 SVIDs × 1 Hz × 600s
}

// With ConsistentHash: Random distribution, may overload one worker
// With RoundRobin: Alternates, may overload one worker
// With WeightedConsistentHash: Balanced total weight, fair distribution
```

---

**Please review and answer all questions marked `[PLEASE RESPOND HERE]`. Once we have alignment, I'll proceed with implementation.**
